import argparse
import json
import os
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer
import google.generativeai as genai

# Custom imports
from Config import Config
from Exceptions import (
    ConfigurationError, 
    RAGServiceError, 
    FileNotFoundError, 
    ModelLoadError, 
    APIError,
    ValidationError
)
from Logger import Logger

def load_index_and_chunks():
    """FAISS index ve chunks dosyalarÄ±nÄ± gÃ¼venli ÅŸekilde yÃ¼kler"""
    try:
        Logger.info("FAISS index ve chunks dosyalarÄ± yÃ¼kleniyor...")
        
        # Config'den dosya yollarÄ±nÄ± al
        rag_config = Config.get_rag_config()
        index_path = rag_config['index_path']
        chunks_path = rag_config['chunks_path']
        
        # DosyalarÄ±n varlÄ±ÄŸÄ±nÄ± kontrol et
        if not os.path.exists(index_path):
            raise FileNotFoundError(f"FAISS index dosyasÄ± bulunamadÄ±: {index_path}")
        
        if not os.path.exists(chunks_path):
            raise FileNotFoundError(f"Chunks dosyasÄ± bulunamadÄ±: {chunks_path}")
        
        # DosyalarÄ± yÃ¼kle
        index = faiss.read_index(index_path)
        with open(chunks_path, 'r', encoding='utf-8') as f:
            chunks = json.load(f)
        
        Logger.info(f"BaÅŸarÄ±yla yÃ¼klendi: {len(chunks)} chunk, index boyutu: {index.ntotal}")
        return index, chunks
        
    except FileNotFoundError as e:
        Logger.error(f"Dosya bulunamama hatasÄ±: {e}")
        raise FileNotFoundError(f"Gerekli dosyalar bulunamadÄ±: {e}")
    except Exception as e:
        Logger.error(f"Index ve chunks yÃ¼kleme hatasÄ±: {e}")
        raise RAGServiceError(f"Index ve chunks yÃ¼klenemedi: {e}")

def get_top_chunks(question, model, index, chunks, top_k=5):
    """Soru iÃ§in en alakalÄ± chunk'larÄ± bulur"""
    try:
        Logger.debug(f"Soru iÃ§in en alakalÄ± {top_k} chunk aranÄ±yor...")
        
        # Input validation
        if not question or not question.strip():
            raise ValidationError("Soru boÅŸ olamaz")
        
        if not chunks or len(chunks) == 0:
            raise ValidationError("Chunks listesi boÅŸ")
        
        # Embedding oluÅŸtur
        q_vec = model.encode([question], convert_to_numpy=True)
        
        # FAISS search
        D, I = index.search(q_vec, min(top_k, len(chunks)))
        top_chunks = [chunks[i] for i in I[0]]
        
        Logger.debug(f"{len(top_chunks)} alakalÄ± chunk bulundu")
        return top_chunks
        
    except Exception as e:
        Logger.error(f"Top chunks bulma hatasÄ±: {e}")
        raise RAGServiceError(f"AlakalÄ± chunk'lar bulunamadÄ±: {e}")

def build_improved_prompt(question, top_chunks, product_stats):
    """
    Gemini iÃ§in geliÅŸtirilmiÅŸ bir prompt oluÅŸturur.
    
    Args:
        question (str): KullanÄ±cÄ±nÄ±n sorusu.
        top_chunks (list): RAG ile Ã§ekilmiÅŸ en ilgili yorum parÃ§alarÄ±.
        product_stats (dict): Ortalama puan, yorum sayÄ±sÄ± gibi istatistiksel veriler.
    """
    # TÃ¼m yorumlarÄ± numaralandÄ±rarak gÃ¶ster
    context = '\n'.join(f'{i+1}. {c}' for i, c in enumerate(top_chunks))
    
    prompt = (
        "Sen, e-ticaret sitelerindeki Ã¼rÃ¼n yorumlarÄ±nÄ± analiz eden uzman bir yapay zeka asistanÄ±sÄ±n. "
        "GÃ¶revin, kullanÄ±cÄ± yorumlarÄ±nÄ± analiz ederek kÄ±sa ve Ã¶z bir genel deÄŸerlendirme sunmaktÄ±r.\n\n"
        "**ÃœRÃœNÃœN GENEL PUAN DURUMU:**\n"
        f"- Ortalama Puan: {product_stats.get('ortalamaPuan', 'N/A')} / 5\n"
        f"- Toplam DeÄŸerlendirme SayÄ±sÄ±: {product_stats.get('toplamDegerlendirme', 'N/A')}\n"
        f"- Pozitif Yorumlar: {product_stats.get('pozitifYorumlar', 'N/A')}\n"
        f"- Negatif Yorumlar: {product_stats.get('negatifYorumlar', 'N/A')}\n\n"
        "**KULLANICI YORUMLARI:**\n"
        f"{context}\n\n"
        f"**TOPLAM YORUM SAYISI:** {len(top_chunks)} adet yorum bulunmaktadÄ±r.\n\n"
        "--- GÃ–REV ve KURALLAR ---\n"
        "1. **Sadece SaÄŸlanan Bilgiyi Kullan:** CevabÄ±nÄ± SADECE yukarÄ±daki bilgilere dayandÄ±r.\n"
        "2. **KÄ±sa ve Ã–z Ol:** Maksimum 3-4 paragraf yaz.\n"
        "3. **Dengeli BakÄ±ÅŸ AÃ§Ä±sÄ±:** Hem olumlu hem olumsuz yÃ¶nleri kÄ±saca belirt.\n"
        "4. **Genel DeÄŸerlendirme FormatÄ±:**\n"
        "    - **Genel DeÄŸerlendirme:** YorumlarÄ±n genel havasÄ±nÄ± Ã¶zetleyen kÄ±sa bir paragraf (olumlu/olumsuz yÃ¶nler dahil).\n"
        "    - **SonuÃ§:** KÄ±sa bir tavsiye veya Ã¶zet.\n"
        "5. **Gereksiz Detaylardan KaÃ§Ä±n:** Uzun listeler ve Ã§ok fazla alÄ±ntÄ± yapma.\n"
        "-----------------------------------\n\n"
        f"**KULLANICININ SORUSU:** {question}\n\n"
        "**GENEL DEÄERLENDÄ°RME (KÄ±sa ve Ã¶z, TÃ¼rkÃ§e):**"
    )
    return prompt

def build_prompt(question, top_chunks):
    """Eski prompt fonksiyonu - geriye uyumluluk iÃ§in"""
    return build_improved_prompt(question, top_chunks, {})

def extract_product_stats(chunks):
    """Yorumlardan Ã¼rÃ¼n istatistiklerini Ã§Ä±karÄ±r"""
    stats = {
        'ortalamaPuan': 0,
        'toplamDegerlendirme': len(chunks),
        'pozitifYorumlar': 0,
        'negatifYorumlar': 0,
        'nÃ¶trYorumlar': 0
    }
    
    total_rating = 0
    rating_count = 0
    
    for chunk in chunks:
        # Rating bilgisi varsa topla
        if 'rate' in chunk and chunk['rate'] > 0:
            total_rating += chunk['rate']
            rating_count += 1
        
        # Yorum tonunu analiz et
        text = chunk.lower()
        positive_words = ['gÃ¼zel', 'iyi', 'beÄŸendim', 'memnun', 'kaliteli', 'tavsiye', 'harika', 'mÃ¼kemmel']
        negative_words = ['kÃ¶tÃ¼', 'berbat', 'memnun deÄŸil', 'kÄ±rÄ±k', 'bozuk', 'iade']
        
        positive_count = sum(1 for word in positive_words if word in text)
        negative_count = sum(1 for word in negative_words if word in text)
        
        if positive_count > negative_count:
            stats['pozitifYorumlar'] += 1
        elif negative_count > positive_count:
            stats['negatifYorumlar'] += 1
        else:
            stats['nÃ¶trYorumlar'] += 1
    
    if rating_count > 0:
        stats['ortalamaPuan'] = round(total_rating / rating_count, 1)
    
    return stats

def add_review_count_to_response(response_text, total_chunks, used_chunks):
    """AI cevabÄ±nÄ±n sonuna yorum sayÄ±sÄ±nÄ± ekler"""
    review_count_info = f"\n\n---\nğŸ“Š **Test Bilgisi**: Bu analiz {used_chunks}/{total_chunks} yorumdan oluÅŸturulmuÅŸtur."
    return response_text + review_count_info

def main():
    """Ana fonksiyon - gÃ¼venli hata yÃ¶netimi ile"""
    try:
        # Argument parsing
        parser = argparse.ArgumentParser()
        parser.add_argument('--question', required=True, help='KullanÄ±cÄ± sorusu')
        args = parser.parse_args()

        Logger.info("RAG sorgu sistemi baÅŸlatÄ±lÄ±yor...")
        
        # KonfigÃ¼rasyonu doÄŸrula
        try:
            Config.validate()
            Logger.info("KonfigÃ¼rasyon doÄŸrulandÄ±")
        except ValueError as e:
            Logger.critical(f"KonfigÃ¼rasyon hatasÄ±: {e}")
            print(f'Hata: {e}', flush=True)
            exit(1)

        # Gemini API'yi konfigÃ¼re et
        try:
            model_config = Config.get_model_config()
            genai.configure(api_key=model_config['api_key'])
            Logger.info("Gemini API konfigÃ¼re edildi")
        except Exception as e:
            Logger.error(f"Gemini API konfigÃ¼rasyon hatasÄ±: {e}")
            raise ConfigurationError(f"Gemini API konfigÃ¼re edilemedi: {e}")

        # Sentence Transformer modelini yÃ¼kle
        try:
            rag_config = Config.get_rag_config()
            model = SentenceTransformer(rag_config['sentence_transformer_model'])
            Logger.info(f"Sentence Transformer modeli yÃ¼klendi: {rag_config['sentence_transformer_model']}")
        except Exception as e:
            Logger.error(f"Model yÃ¼kleme hatasÄ±: {e}")
            raise ModelLoadError(f"Sentence Transformer modeli yÃ¼klenemedi: {e}")

        # Index ve chunks'larÄ± yÃ¼kle
        try:
            index, chunks = load_index_and_chunks()
        except (FileNotFoundError, RAGServiceError) as e:
            Logger.error(f"Index yÃ¼kleme hatasÄ±: {e}")
            print(f'Hata: {e}', flush=True)
            exit(1)

        # YorumlarÄ± formatla
        try:
            all_reviews = []
            for i, chunk in enumerate(chunks):
                if isinstance(chunk, dict):
                    review_text = f"YORUM {i+1}: "
                    if 'comment' in chunk:
                        review_text += chunk['comment']
                    if 'rate' in chunk and chunk['rate'] > 0:
                        review_text += f" (Puan: {chunk['rate']}/5)"
                    if 'user' in chunk and chunk['user'] != 'Anonim':
                        review_text += f" (KullanÄ±cÄ±: {chunk['user']})"
                    all_reviews.append(review_text)
                elif isinstance(chunk, str):
                    all_reviews.append(f"YORUM {i+1}: {chunk}")
            
            top_chunks = all_reviews
            Logger.info(f"{len(top_chunks)} yorum formatlandÄ±")
        except Exception as e:
            Logger.error(f"Yorum formatlama hatasÄ±: {e}")
            raise RAGServiceError(f"Yorumlar formatlanamadÄ±: {e}")

        # ÃœrÃ¼n istatistiklerini Ã§Ä±kar
        try:
            product_stats = extract_product_stats(chunks)
            Logger.debug(f"ÃœrÃ¼n istatistikleri Ã§Ä±karÄ±ldÄ±: {product_stats}")
        except Exception as e:
            Logger.warning(f"Ä°statistik Ã§Ä±karma hatasÄ±, varsayÄ±lan deÄŸerler kullanÄ±lÄ±yor: {e}")
            product_stats = {}

        # Prompt oluÅŸtur
        try:
            prompt = build_improved_prompt(args.question, top_chunks, product_stats)
            Logger.debug("Prompt oluÅŸturuldu")
        except Exception as e:
            Logger.error(f"Prompt oluÅŸturma hatasÄ±: {e}")
            raise RAGServiceError(f"Prompt oluÅŸturulamadÄ±: {e}")

        # Gemini ile yanÄ±t al
        try:
            gemini = genai.GenerativeModel(model_config['model_name'])
            response = gemini.generate_content(prompt)
            
            if not response or not response.text:
                raise APIError("Gemini API'den boÅŸ yanÄ±t alÄ±ndÄ±")
            
            Logger.info("Gemini API'den yanÄ±t alÄ±ndÄ±")
        except Exception as e:
            Logger.error(f"Gemini API hatasÄ±: {e}")
            raise APIError(f"AI yanÄ±tÄ± alÄ±namadÄ±: {e}")

        # Final yanÄ±tÄ± oluÅŸtur
        try:
            final_response = add_review_count_to_response(
                response.text.strip(), 
                len(chunks), 
                len(top_chunks)
            )
            print(final_response, flush=True)
            Logger.info("RAG sorgu iÅŸlemi baÅŸarÄ±yla tamamlandÄ±")
            
        except Exception as e:
            Logger.error(f"Final yanÄ±t oluÅŸturma hatasÄ±: {e}")
            print(f'Hata: Final yanÄ±t oluÅŸturulamadÄ±: {e}', flush=True)
            exit(1)

    except (ConfigurationError, ModelLoadError, RAGServiceError, APIError) as e:
        Logger.error(f"Kritik hata: {e}")
        print(f'Hata: {e}', flush=True)
        exit(1)
    except Exception as e:
        Logger.critical(f"Beklenmeyen hata: {e}")
        print(f'Beklenmeyen hata: {e}', flush=True)
        exit(1)

if __name__ == "__main__":
    main()
