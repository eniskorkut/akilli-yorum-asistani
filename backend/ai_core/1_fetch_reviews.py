# Akilli Yorum Asistani - Yorum Ã‡ekme ModÃ¼lÃ¼
# Bu dosya Trendyol ve Hepsiburada Ã¼rÃ¼n sayfalarÄ±ndan yorumlarÄ± Ã§eker
# Web scraping ve API kullanarak yorumlarÄ± toplar
# Hackathon Projesi - AI Destekli Yorum Analizi
# 
# Ã–zellikler:
# - Trendyol API entegrasyonu
# - Hepsiburada Selenium scraper
# - Otomatik site algÄ±lama
# - Ã‡oklu veri kaynaÄŸÄ± desteÄŸi
# 
# KullanÄ±m:
# python 1_fetch_reviews.py --url "https://www.trendyol.com/urun-url" --max-reviews 50
# python 1_fetch_reviews.py --url "https://www.hepsiburada.com/urun-url" --max-reviews 50
#
# Gereksinimler:
# - requests
# - selenium
# - beautifulsoup4
# - webdriver-manager
#
# Lisans: MIT
# Yazar: AkÄ±llÄ± Yorum AsistanÄ± Projesi

import requests
import json
import argparse
import re
import time
from urllib.parse import urlparse, parse_qs
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
import bs4
from bs4 import BeautifulSoup

# Hepsiburada scraper modÃ¼lÃ¼nÃ¼ import et
try:
    from hepsiburada_scraper import fetch_reviews_hepsiburada
except ImportError:
    # EÄŸer hepsiburada_scraper modÃ¼lÃ¼ yoksa, bu fonksiyonu burada tanÄ±mlayacaÄŸÄ±z
    pass

# TRENDYOL API YAKLAÅIMI
# URL'den alÄ±nan product_slug ve merchant_id'yi kullanarak sayfa sayfa yorum Ã§eker
# Trendyol'un resmi API'sini kullanarak hÄ±zlÄ± ve gÃ¼venilir veri Ã§ekimi
API_URL = "https://apigw.trendyol.com/discovery-web-socialgw-service/reviews/{product_slug}/yorumlar?merchantId={merchantId}&page={page}&culture=tr-TR&storefrontId=1"

# HTTP istekleri iÃ§in header bilgileri - GerÃ§ek tarayÄ±cÄ± gibi davranmak iÃ§in
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
    "Accept": "application/json, text/plain, */*",
    "Accept-Language": "tr-TR,tr;q=0.9,en;q=0.8",
    "Referer": "https://www.trendyol.com/",
    "Origin": "https://www.trendyol.com"
}

def detect_site_from_url(url):
    """
    URL'den hangi site olduÄŸunu algÄ±lar
    """
    if not url:
        return None
    
    url_lower = url.lower()
    
    if 'trendyol.com' in url_lower:
        return {
            'site': 'trendyol',
            'name': 'Trendyol',
            'scraper_script': '1_fetch_reviews.py'
        }
    elif 'hepsiburada.com' in url_lower:
        return {
            'site': 'hepsiburada',
            'name': 'Hepsiburada',
            'scraper_script': '1_fetch_reviews_hepsiburada.py'
        }
    
    return None

def extract_product_info_from_url(url):
    """
    Trendyol URL'sinden Ã¼rÃ¼n slug'Ä±nÄ± ve merchant ID'yi gÃ¼venilir ÅŸekilde Ã§Ä±karÄ±r.
    Bu fonksiyon URL parsing yaparak API Ã§aÄŸrÄ±larÄ± iÃ§in gerekli parametreleri elde eder.
    
    Ã–rnek URL: https://www.trendyol.com/harmana/hindiba-kahvesi-p-288620006?boutiqueId=61&merchantId=936059
    """
    try:
        print(f"URL ayrÄ±ÅŸtÄ±rÄ±lÄ±yor: {url}")
        parsed_url = urlparse(url)
        
        # product_slug: URL'nin path kÄ±smÄ±dÄ±r (Ã¶rn: /harmana/hindiba-kahvesi-p-288620006)
        product_slug = parsed_url.path.strip('/')
        if not product_slug:
            print("URL'den Ã¼rÃ¼n slug'Ä± Ã§Ä±karÄ±lamadÄ±.")
            return None, None
            
        # merchantId: URL'nin query parametrelerinden alÄ±nÄ±r
        query_params = parse_qs(parsed_url.query)
        merchant_id = query_params.get('merchantId', [None])[0]
        
        if not merchant_id:
            print("URL'den merchantId bulunamadÄ±. Sayfa kaynaÄŸÄ±ndan alÄ±nmaya Ã§alÄ±ÅŸÄ±lacak.")
            # EÄŸer URL'de merchantId yoksa, bazen ana Ã¼rÃ¼n sayfasÄ±nda bulunur
            # Bu durumu ÅŸimdilik None olarak geÃ§iyoruz, API denemesi baÅŸarÄ±sÄ±z olursa Selenium devreye girer
            pass

        print(f"Bulunan slug: {product_slug}, merchant_id: {merchant_id}")
        return product_slug, merchant_id
        
    except Exception as e:
        print(f"URL ayrÄ±ÅŸtÄ±rma hatasÄ±: {e}")
        return None, None

def fetch_reviews_api(product_slug, merchant_id, max_pages=10):
    """
    Trendyol API kullanarak yorumlarÄ± Ã§eker (YENÄ° YÃ–NTEM)
    Bu fonksiyon resmi API'yi kullanarak hÄ±zlÄ± ve gÃ¼venilir veri Ã§ekimi yapar
    """
    reviews = []
    page = 0
    total_pages = 1
    
    # API isteÄŸi iÃ§in merchantId gerekli
    if not merchant_id:
        print("API isteÄŸi iÃ§in merchantId gerekli, bu adÄ±m atlanÄ±yor.")
        return []

    print(f"API ile yorumlar Ã§ekiliyor: {product_slug} (Merchant: {merchant_id})")
    
    # Sayfa sayfa yorumlarÄ± Ã§ek
    while page < total_pages and page < max_pages:
        try:
            # Sayfa numarasÄ±nÄ± URL'ye ekle
            url = API_URL.format(product_slug=product_slug, merchantId=merchant_id, page=page)
            print(f"API URL: {url}")
            
            # HTTP session oluÅŸtur ve header'larÄ± ayarla
            session = requests.Session()
            session.headers.update(HEADERS)
            
            # API'ye istek gÃ¶nder
            resp = session.get(url, timeout=30)
            
            if resp.status_code != 200:
                print(f"Sayfa {page} Ã§ekilemedi: {resp.status_code}")
                print(f"Response: {resp.text[:200]}")
                break
                
            data = resp.json()
            
            # Gelen yanÄ±tta hata olup olmadÄ±ÄŸÄ±nÄ± kontrol et
            if not data.get('isSuccess') or 'result' not in data:
                print(f"API'den baÅŸarÄ±sÄ±z yanÄ±t alÄ±ndÄ±: {data.get('error')}")
                break

            review_data = data['result'].get('productReviews', {})
            
            if page == 0:
                # Toplam sayfa sayÄ±sÄ±nÄ± yanÄ±ttan al
                total_pages = min(review_data.get('totalPages', 1), max_pages)
                print(f"Toplam {total_pages} sayfa bulundu.")

            # YorumlarÄ± Ã§Ä±kar
            page_reviews = review_data.get('reviews', [])
            if not page_reviews:
                print(f"Sayfa {page} iÃ§in yorum bulunamadÄ±.")
                break

            # YorumlarÄ± iÅŸle
            for review in page_reviews:
                if len(reviews) >= 100:  # Maksimum yorum sayÄ±sÄ±
                    break
                    
                comment = review.get('comment', '').strip()
                if comment:
                    reviews.append({
                        'comment': comment,
                        'rating': review.get('rating', 0),
                        'user': review.get('userFullName', 'Anonim'),
                        'date': review.get('commentDate', ''),
                        'source': 'trendyol_api'
                    })

            print(f"Sayfa {page + 1}: {len(page_reviews)} yorum Ã§ekildi. Toplam: {len(reviews)}")
            page += 1
            
            # Rate limiting - API'yi Ã§ok hÄ±zlÄ± Ã§aÄŸÄ±rmamak iÃ§in
            time.sleep(0.5)
            
        except requests.exceptions.RequestException as e:
            print(f"API isteÄŸi hatasÄ± (sayfa {page}): {e}")
            break
        except json.JSONDecodeError as e:
            print(f"JSON parse hatasÄ± (sayfa {page}): {e}")
            break
        except Exception as e:
            print(f"Beklenmeyen hata (sayfa {page}): {e}")
            break

    print(f"API ile toplam {len(reviews)} yorum Ã§ekildi.")
    return reviews


def fetch_reviews_selenium(url, max_reviews=100):
    """Selenium ile web scraping yaparak yorumlarÄ± Ã§eker (GÃœÃ‡LENDÄ°RÄ°LMÄ°Å YÃ–NTEM)"""
    reviews = []
    
    print(f"Selenium ile yorumlar Ã§ekiliyor: {url}")
    
    try:
        chrome_options = Options()
        chrome_options.add_argument("--headless")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--disable-blink-features=AutomationControlled")
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        chrome_options.add_argument(f"user-agent={HEADERS['User-Agent']}")
        
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=chrome_options)
        driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        
        # URL'yi yorumlar sayfasÄ±na Ã§evir
        if '/yorumlar' not in url:
            url = url.replace('?', '/yorumlar?')
        
        driver.get(url)
        wait = WebDriverWait(driver, 20)
        
        # SayfanÄ±n yÃ¼klenmesini bekle
        time.sleep(5)
        
        # YorumlarÄ± bulmak iÃ§in farklÄ± selector'larÄ± dene
        review_selectors = [
            '[data-testid="review-card"]',
            '.review-card',
            '.r-card',
            '[class*="review"]',
            '[class*="comment"]',
            '.comment-item',
            '.review-item'
        ]
        
        review_elements = []
        for selector in review_selectors:
            try:
                elements = driver.find_elements(By.CSS_SELECTOR, selector)
                if elements:
                    print(f"Yorumlar bulundu: {selector} ile {len(elements)} adet")
                    review_elements = elements
                    break
            except:
                continue
        
        if not review_elements:
            # SayfayÄ± scroll et ve tekrar dene
            print("Ä°lk denemede yorum bulunamadÄ±, sayfa scroll ediliyor...")
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(3)
            
            for selector in review_selectors:
                try:
                    elements = driver.find_elements(By.CSS_SELECTOR, selector)
                    if elements:
                        print(f"Scroll sonrasÄ± yorumlar bulundu: {selector} ile {len(elements)} adet")
                        review_elements = elements
                        break
                except:
                    continue
        
        # YorumlarÄ± iÅŸle
        processed_count = 0
        for element in review_elements:
            try:
                processed_count += 1
                print(f"Element {processed_count}/{len(review_elements)} iÅŸleniyor...")
                
                # GÃœÃ‡LENDÄ°RÄ°LMÄ°Å YORUM Ã‡IKARMA SÄ°STEMÄ°
                comment_text = ""
                
                # 1. AdÄ±m: Ã–zel Trendyol selector'larÄ±
                trendyol_selectors = [
                    '[data-testid="review-comment"]',
                    '.review-comment',
                    '.comment-text',
                    '.r-card-text',
                    '[class*="comment"]',
                    '[class*="review-text"]',
                    '.review-content',
                    '.comment-content',
                    '[data-testid="comment"]'
                ]
                
                for selector in trendyol_selectors:
                    try:
                        comment_elem = element.find_element(By.CSS_SELECTOR, selector)
                        text = comment_elem.text.strip()
                        if len(text) > 5 and not any(word in text.lower() for word in ['saÄŸlÄ±k beyanÄ±', 'fotoÄŸraflÄ±', 'tÃ¼mÃ¼']):
                            comment_text = text
                            print(f"Yorum bulundu ({selector}): {text[:50]}...")
                            break
                    except:
                        continue
                
                # 2. AdÄ±m: Genel text elementleri (eÄŸer Ã¶zel selector'lar baÅŸarÄ±sÄ±zsa)
                if not comment_text:
                    try:
                        # Element iÃ§indeki tÃ¼m text'leri topla
                        all_texts = element.find_elements(By.CSS_SELECTOR, 'p, span, div, h3, h4, h5')
                        for text_elem in all_texts:
                            text = text_elem.text.strip()
                            if len(text) > 10 and len(text) < 500:  # Makul yorum uzunluÄŸu
                                # AlakasÄ±z iÃ§erikleri filtrele
                                if not any(word in text.lower() for word in [
                                    'saÄŸlÄ±k beyanÄ±', 'fotoÄŸraflÄ±', 'tÃ¼mÃ¼',
                                    'boutique', 'merchant', 'storefront', 'culture', 'logged-in',
                                    'isbuyer', 'channel', 'socialproof', 'abtesting'
                                ]):
                                    comment_text = text
                                    print(f"Genel text bulundu: {text[:50]}...")
                                    break
                    except:
                        pass
                
                # 3. AdÄ±m: Element'in kendisinden text Ã§Ä±kar
                if not comment_text:
                    try:
                        full_text = element.text.strip()
                        # Text'i satÄ±rlara bÃ¶l ve en uzun satÄ±rÄ± al
                        lines = [line.strip() for line in full_text.split('\n') if line.strip()]
                        if lines:
                            longest_line = max(lines, key=len)
                            if len(longest_line) > 5 and len(longest_line) < 500:
                                if not any(word in longest_line.lower() for word in [
                                    'saÄŸlÄ±k beyanÄ±', 'fotoÄŸraflÄ±', 'tÃ¼mÃ¼'
                                ]):
                                    comment_text = longest_line
                                    print(f"En uzun satÄ±r bulundu: {longest_line[:50]}...")
                    except:
                        pass
                
                if comment_text and len(comment_text) > 3:  # Ã‡ok daha gevÅŸek filtreleme
                    # PuanÄ± bul
                    rate = 0
                    try:
                        star_elements = element.find_elements(By.CSS_SELECTOR, '[class*="star"], [class*="rating"]')
                        if star_elements:
                            rate = len([s for s in star_elements if 'filled' in s.get_attribute('class') or 'active' in s.get_attribute('class')])
                    except:
                        pass
                    
                    # KullanÄ±cÄ± adÄ±nÄ± bul
                    user_name = "Anonim"
                    try:
                        user_elements = element.find_elements(By.CSS_SELECTOR, '[class*="user"], [class*="author"]')
                        if user_elements:
                            user_name = user_elements[0].text.strip()
                    except:
                        pass
                    
                    # Tekrar eden yorumlarÄ± kontrol et
                    if not any(r['comment'] == comment_text for r in reviews):
                        reviews.append({
                            'comment': comment_text,
                            'rate': rate,
                            'user': user_name,
                            'date': '',
                            'source': 'selenium_improved'
                        })
                        print(f"Yorum eklendi ({len(comment_text)} karakter): {comment_text[:50]}...")
                
            except Exception as e:
                print(f"Yorum iÅŸleme hatasÄ±: {e}")
                continue
            
            if len(reviews) >= max_reviews:
                break
        
        # Daha fazla yorum iÃ§in sayfayÄ± scroll et
        if len(reviews) < max_reviews:
            print("Daha fazla yorum iÃ§in sayfa scroll ediliyor...")
            last_height = driver.execute_script("return document.body.scrollHeight")
            previous_review_count = len(reviews)
            no_change_count = 0
            
            for scroll_attempt in range(50):  # 50 kez scroll dene (Ã¶nceki Ã§alÄ±ÅŸan versiyon)
                print(f"Scroll denemesi {scroll_attempt + 1}/50...")
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(1)  # Daha hÄ±zlÄ± scroll
                
                # "Daha Fazla GÃ¶ster" butonlarÄ±nÄ± tÄ±kla
                try:
                    load_more_buttons = driver.find_elements(By.CSS_SELECTOR, '[class*="load"], [class*="more"], [class*="show"]')
                    for button in load_more_buttons:
                        if button.is_displayed() and button.is_enabled():
                            driver.execute_script("arguments[0].click();", button)
                            print("Daha fazla gÃ¶ster butonu tÄ±klandÄ±")
                            time.sleep(1)
                except:
                    pass
                
                # Yeni yorumlarÄ± kontrol et
                for selector in review_selectors:
                    try:
                        new_elements = driver.find_elements(By.CSS_SELECTOR, selector)
                        if len(new_elements) > len(review_elements):
                            print(f"Yeni yorumlar bulundu: {len(new_elements)} adet")
                            review_elements = new_elements
                            
                            # TÃœM elementlerden yorumlarÄ± Ã§Ä±kar (yeni + eski)
                            for new_element in review_elements:
                                try:
                                    # AynÄ± gÃ¼Ã§lendirilmiÅŸ yorum Ã§Ä±karma sistemini kullan
                                    comment_text = ""
                                    
                                    # 1. AdÄ±m: Ã–zel Trendyol selector'larÄ±
                                    for selector_name in trendyol_selectors:
                                        try:
                                            comment_elem = new_element.find_element(By.CSS_SELECTOR, selector_name)
                                            text = comment_elem.text.strip()
                                            if len(text) > 5 and not any(word in text.lower() for word in ['saÄŸlÄ±k beyanÄ±', 'fotoÄŸraflÄ±', 'tÃ¼mÃ¼']):
                                                comment_text = text
                                                break
                                        except:
                                            continue
                                    
                                    # 2. AdÄ±m: Genel text elementleri
                                    if not comment_text:
                                        try:
                                            all_texts = new_element.find_elements(By.CSS_SELECTOR, 'p, span, div, h3, h4, h5')
                                            for text_elem in all_texts:
                                                text = text_elem.text.strip()
                                                if len(text) > 10 and len(text) < 500:
                                                    if not any(word in text.lower() for word in [
                                                        'saÄŸlÄ±k beyanÄ±', 'fotoÄŸraflÄ±', 'tÃ¼mÃ¼',
                                                        'boutique', 'merchant', 'storefront', 'culture', 'logged-in',
                                                        'isbuyer', 'channel', 'socialproof', 'abtesting'
                                                    ]):
                                                        comment_text = text
                                                        break
                                        except:
                                            pass
                                    
                                    # 3. AdÄ±m: Element'in kendisinden text Ã§Ä±kar
                                    if not comment_text:
                                        try:
                                            full_text = new_element.text.strip()
                                            lines = [line.strip() for line in full_text.split('\n') if line.strip()]
                                            if lines:
                                                longest_line = max(lines, key=len)
                                                if len(longest_line) > 5 and len(longest_line) < 500:
                                                    if not any(word in longest_line.lower() for word in [
                                                        'saÄŸlÄ±k beyanÄ±', 'fotoÄŸraflÄ±', 'tÃ¼mÃ¼'
                                                    ]):
                                                        comment_text = longest_line
                                        except:
                                            pass
                                    
                                    if comment_text and len(comment_text) > 3:  # Ã‡ok daha gevÅŸek filtreleme
                                        # Tekrar eden yorumlarÄ± kontrol et
                                        if not any(r['comment'] == comment_text for r in reviews):
                                            reviews.append({
                                                'comment': comment_text,
                                                'rate': 0,
                                                'user': 'Anonim',
                                                'date': '',
                                                'source': 'selenium_scroll'
                                            })
                                            print(f"Scroll ile yorum eklendi ({len(comment_text)} karakter): {comment_text[:50]}...")
                                            
                                            # Limit kaldÄ±rÄ±ldÄ± - tÃ¼m yorumlarÄ± topla
                                            pass
                                except Exception as e:
                                    continue
                            
                            # Limit kaldÄ±rÄ±ldÄ± - tÃ¼m yorumlarÄ± topla
                            pass
                    except:
                        continue
                
                new_height = driver.execute_script("return document.body.scrollHeight")
                current_review_count = len(reviews)
                print(f"Scroll {scroll_attempt + 1}: {current_review_count} yorum toplandÄ±")
                
                # EÄŸer son 5 scroll'da yorum sayÄ±sÄ± artmadÄ±ysa dur
                if scroll_attempt >= 5 and current_review_count == previous_review_count:
                    no_change_count += 1
                    if no_change_count >= 5:
                        print("Yorum sayÄ±sÄ± artmÄ±yor, scroll durduruluyor...")
                        break
                else:
                    no_change_count = 0
                
                previous_review_count = current_review_count
                
                if new_height == last_height:
                    print("Sayfa sonuna ulaÅŸÄ±ldÄ±, scroll durduruluyor...")
                    break
                last_height = new_height
                
                if len(reviews) >= max_reviews:
                    break

        driver.quit()
        print(f"Selenium ile toplam {len(reviews)} yorum Ã§ekildi")
        
    except Exception as e:
        print(f"Selenium baÅŸlatma/Ã§alÄ±ÅŸma hatasÄ±: {e}")
        if 'driver' in locals() and driver:
            driver.quit()
    
    return reviews


def fetch_reviews(url=None, max_pages=10, max_reviews=100):
    """
    Ana yorum Ã§ekme fonksiyonu - Hem Trendyol hem de Hepsiburada desteÄŸi
    """
    reviews = []
    
    if not url:
        print("URL parametresi gerekli.")
        return []
    
    # URL'den hangi site olduÄŸunu algÄ±la
    site_info = detect_site_from_url(url)
    if not site_info:
        print("Desteklenmeyen site. Sadece Trendyol ve Hepsiburada desteklenir.")
        return []
    
    print(f"AlgÄ±lanan site: {site_info['name']}")
    
    if site_info['site'] == 'trendyol':
        # Trendyol iÃ§in yorum Ã§ekme
        product_slug, merchant_id = extract_product_info_from_url(url)
        
        if not product_slug:
            print("URL'den Ã¼rÃ¼n bilgisi alÄ±namadÄ±.")
            return []

        # Ã–nce API ile dene
        if merchant_id:
            print("Trendyol API ile yorumlar Ã§ekiliyor...")
            reviews = fetch_reviews_api(product_slug, merchant_id, max_pages)
        
        # API baÅŸarÄ±sÄ±z olursa veya yeterli yorum yoksa Selenium kullan
        if not reviews or len(reviews) < 10:
            print("API yeterli yorum saÄŸlamadÄ±, Selenium ile devam ediliyor...")
            selenium_reviews = fetch_reviews_selenium(url, max_reviews)
            reviews.extend(selenium_reviews)
    
    elif site_info['site'] == 'hepsiburada':
        # Hepsiburada iÃ§in yorum Ã§ekme
        print("Hepsiburada yorumlarÄ± Ã§ekiliyor...")
        try:
            from hepsiburada_scraper import fetch_reviews_hepsiburada
            reviews = fetch_reviews_hepsiburada(url, max_reviews)
        except ImportError:
            print("Hepsiburada scraper modÃ¼lÃ¼ bulunamadÄ±, Selenium ile devam ediliyor...")
            reviews = fetch_reviews_selenium(url, max_reviews)
    
    # SonuÃ§larÄ± kaydet
    if reviews:
        # Tekrar eden yorumlarÄ± temizle
        unique_reviews = []
        seen_comments = set()
        
        for review in reviews:
            comment = review.get('comment', '').strip()
            if comment and comment not in seen_comments and len(comment) > 10:
                unique_reviews.append(review)
                seen_comments.add(comment)
        
        print(f"\nToplam {len(unique_reviews)} adet benzersiz yorum bulundu ve kaydediliyor.")
        
        # YorumlarÄ± JSON dosyasÄ±na kaydet
        with open('reviews.json', 'w', encoding='utf-8') as f:
            json.dump(unique_reviews, f, ensure_ascii=False, indent=2)
        
        print("Yorumlar 'reviews.json' dosyasÄ±na baÅŸarÄ±yla kaydedildi.")
        return unique_reviews
    else:
        print("\nHiÃ§ yorum Ã§ekilemedi.")
        return []

def main():
    parser = argparse.ArgumentParser(description='Trendyol ve Hepsiburada Ã¼rÃ¼n yorumlarÄ±nÄ± Ã§eker')
    parser.add_argument('--url', required=True, help='Trendyol veya Hepsiburada Ã¼rÃ¼n URL\'si')
    parser.add_argument('--max-pages', type=int, default=10, help='API iÃ§in maksimum sayfa sayÄ±sÄ±')
    parser.add_argument('--max-reviews', type=int, default=100, help='Maksimum yorum sayÄ±sÄ±')
    
    args = parser.parse_args()
    
    # URL'den site algÄ±lama
    site_info = detect_site_from_url(args.url)
    if not site_info:
        print("Hata: Desteklenmeyen site. Sadece Trendyol ve Hepsiburada desteklenir.")
        return
    
    print(f"Site algÄ±landÄ±: {site_info['name']}")
    print(f"URL: {args.url}")
    print(f"Maksimum yorum sayÄ±sÄ±: {args.max_reviews}")
    
    # YorumlarÄ± Ã§ek
    reviews = fetch_reviews(args.url, args.max_pages, args.max_reviews)
    
    if reviews:
        print(f"\nâœ… BaÅŸarÄ±lÄ±! Toplam {len(reviews)} yorum Ã§ekildi.")
        print(f"ğŸ“ Yorumlar 'reviews.json' dosyasÄ±na kaydedildi.")
    else:
        print("\nâŒ HiÃ§ yorum Ã§ekilemedi.")

if __name__ == "__main__":
    main()