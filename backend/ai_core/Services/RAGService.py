"""
RAG Service - Retrieval-Augmented Generation iÅŸlemleri iÃ§in service layer
"""

from abc import ABC, abstractmethod
from typing import List, Dict, Any, Optional
import os
import json
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer

from Config import Config
from Exceptions import RAGServiceError, FileNotFoundError, ModelLoadError, ValidationError
from Logger import Logger
from Services.AIService import IAIService


class IRAGService(ABC):
    """RAG Service iÃ§in interface"""
    
    @abstractmethod
    def load_index_and_chunks(self) -> tuple:
        """FAISS index ve chunks dosyalarÄ±nÄ± yÃ¼kler"""
        pass
    
    @abstractmethod
    def get_top_chunks(self, question: str, top_k: int = 5) -> List[str]:
        """Soru iÃ§in en alakalÄ± chunk'larÄ± bulur"""
        pass
    
    @abstractmethod
    def extract_product_stats(self, chunks: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Yorumlardan Ã¼rÃ¼n istatistiklerini Ã§Ä±karÄ±r"""
        pass
    
    @abstractmethod
    def build_prompt(self, question: str, top_chunks: List[str], product_stats: Dict[str, Any]) -> str:
        """AI iÃ§in prompt oluÅŸturur"""
        pass


class RAGService(IRAGService):
    """RAG Service implementasyonu"""
    
    def __init__(self, ai_service: IAIService):
        self._ai_service = ai_service
        self._model = None
        self._index = None
        self._chunks = None
        self._config = Config.get_rag_config()
        self._loaded = False
    
    def _load_sentence_transformer(self) -> None:
        """Sentence Transformer modelini yÃ¼kler"""
        try:
            if self._model is None:
                Logger.info("Sentence Transformer modeli yÃ¼kleniyor...")
                model_name = self._config.get('sentence_transformer_model')
                self._model = SentenceTransformer(model_name)
                Logger.info(f"Sentence Transformer modeli yÃ¼klendi: {model_name}")
        except Exception as e:
            Logger.error(f"Sentence Transformer yÃ¼kleme hatasÄ±: {e}")
            raise ModelLoadError(f"Sentence Transformer modeli yÃ¼klenemedi: {e}")
    
    def load_index_and_chunks(self) -> tuple:
        """FAISS index ve chunks dosyalarÄ±nÄ± gÃ¼venli ÅŸekilde yÃ¼kler"""
        try:
            Logger.info("FAISS index ve chunks dosyalarÄ± yÃ¼kleniyor...")
            
            # Dosya yollarÄ±nÄ± al
            index_path = self._config['index_path']
            chunks_path = self._config['chunks_path']
            
            # DosyalarÄ±n varlÄ±ÄŸÄ±nÄ± kontrol et
            if not os.path.exists(index_path):
                raise FileNotFoundError(f"FAISS index dosyasÄ± bulunamadÄ±: {index_path}")
            
            if not os.path.exists(chunks_path):
                raise FileNotFoundError(f"Chunks dosyasÄ± bulunamadÄ±: {chunks_path}")
            
            # DosyalarÄ± yÃ¼kle (her zaman yeniden yÃ¼kle)
            self._index = faiss.read_index(index_path)
            with open(chunks_path, 'r', encoding='utf-8') as f:
                self._chunks = json.load(f)
            
            self._loaded = True
            Logger.info(f"BaÅŸarÄ±yla yÃ¼klendi: {len(self._chunks)} chunk, index boyutu: {self._index.ntotal}")
            return self._index, self._chunks
            
        except FileNotFoundError as e:
            Logger.error(f"Dosya bulunamama hatasÄ±: {e}")
            raise FileNotFoundError(f"Gerekli dosyalar bulunamadÄ±: {e}")
        except Exception as e:
            Logger.error(f"Index ve chunks yÃ¼kleme hatasÄ±: {e}")
            raise RAGServiceError(f"Index ve chunks yÃ¼klenemedi: {e}")
    
    def get_top_chunks(self, question: str, top_k: int = 5) -> List[str]:
        """Soru iÃ§in en alakalÄ± chunk'larÄ± bulur"""
        try:
            Logger.debug(f"Soru iÃ§in en alakalÄ± {top_k} chunk aranÄ±yor...")
            
            # Input validation
            if not question or not question.strip():
                raise ValidationError("Soru boÅŸ olamaz")
            
            if not self._loaded or not self._chunks or len(self._chunks) == 0:
                raise ValidationError("Chunks listesi boÅŸ veya yÃ¼klenmemiÅŸ")
            
            # Sentence Transformer'Ä± yÃ¼kle
            self._load_sentence_transformer()
            
            # Embedding oluÅŸtur
            q_vec = self._model.encode([question], convert_to_numpy=True)
            
            # FAISS search
            D, I = self._index.search(q_vec, min(top_k, len(self._chunks)))
            top_chunks = [self._chunks[i] for i in I[0]]
            
            Logger.debug(f"{len(top_chunks)} alakalÄ± chunk bulundu")
            return top_chunks
            
        except Exception as e:
            Logger.error(f"Top chunks bulma hatasÄ±: {e}")
            raise RAGServiceError(f"AlakalÄ± chunk'lar bulunamadÄ±: {e}")
    
    def extract_product_stats(self, chunks: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Yorumlardan Ã¼rÃ¼n istatistiklerini Ã§Ä±karÄ±r"""
        try:
            stats = {
                'ortalamaPuan': 0,
                'toplamDegerlendirme': len(chunks),
                'pozitifYorumlar': 0,
                'negatifYorumlar': 0,
                'nÃ¶trYorumlar': 0
            }
            
            total_rating = 0
            rating_count = 0
            
            for chunk in chunks:
                # Rating bilgisi varsa topla
                if isinstance(chunk, dict) and 'rate' in chunk and chunk['rate'] > 0:
                    total_rating += chunk['rate']
                    rating_count += 1
                
                # Yorum tonunu analiz et
                text = str(chunk).lower()
                positive_words = ['gÃ¼zel', 'iyi', 'beÄŸendim', 'memnun', 'kaliteli', 'tavsiye', 'harika', 'mÃ¼kemmel']
                negative_words = ['kÃ¶tÃ¼', 'berbat', 'memnun deÄŸil', 'kÄ±rÄ±k', 'bozuk', 'iade']
                
                positive_count = sum(1 for word in positive_words if word in text)
                negative_count = sum(1 for word in negative_words if word in text)
                
                if positive_count > negative_count:
                    stats['pozitifYorumlar'] += 1
                elif negative_count > positive_count:
                    stats['negatifYorumlar'] += 1
                else:
                    stats['nÃ¶trYorumlar'] += 1
            
            if rating_count > 0:
                stats['ortalamaPuan'] = round(total_rating / rating_count, 1)
            
            Logger.debug(f"ÃœrÃ¼n istatistikleri Ã§Ä±karÄ±ldÄ±: {stats}")
            return stats
            
        except Exception as e:
            Logger.warning(f"Ä°statistik Ã§Ä±karma hatasÄ±, varsayÄ±lan deÄŸerler kullanÄ±lÄ±yor: {e}")
            return {
                'ortalamaPuan': 0,
                'toplamDegerlendirme': len(chunks),
                'pozitifYorumlar': 0,
                'negatifYorumlar': 0,
                'nÃ¶trYorumlar': 0
            }
    
    def build_prompt(self, question: str, top_chunks: List[str], product_stats: Dict[str, Any]) -> str:
        """AI iÃ§in prompt oluÅŸturur"""
        try:
            # TÃ¼m yorumlarÄ± numaralandÄ±rarak gÃ¶ster
            context = '\n'.join(f'{i+1}. {c}' for i, c in enumerate(top_chunks))
            
            prompt = (
                "Sen, e-ticaret sitelerindeki Ã¼rÃ¼n yorumlarÄ±nÄ± analiz eden uzman bir yapay zeka asistanÄ±sÄ±n. "
                "GÃ¶revin, kullanÄ±cÄ± yorumlarÄ±nÄ± analiz ederek kÄ±sa ve Ã¶z bir genel deÄŸerlendirme sunmaktÄ±r.\n\n"
                "**ÃœRÃœNÃœN GENEL PUAN DURUMU:**\n"
                f"- Ortalama Puan: {product_stats.get('ortalamaPuan', 'N/A')} / 5\n"
                f"- Toplam DeÄŸerlendirme SayÄ±sÄ±: {product_stats.get('toplamDegerlendirme', 'N/A')}\n"
                f"- Pozitif Yorumlar: {product_stats.get('pozitifYorumlar', 'N/A')}\n"
                f"- Negatif Yorumlar: {product_stats.get('negatifYorumlar', 'N/A')}\n\n"
                "**KULLANICI YORUMLARI:**\n"
                f"{context}\n\n"
                f"**TOPLAM YORUM SAYISI:** {len(top_chunks)} adet yorum bulunmaktadÄ±r.\n\n"
                "--- GÃ–REV ve KURALLAR ---\n"
                "1. **Sadece SaÄŸlanan Bilgiyi Kullan:** CevabÄ±nÄ± SADECE yukarÄ±daki bilgilere dayandÄ±r.\n"
                "2. **KÄ±sa ve Ã–z Ol:** Maksimum 3-4 paragraf yaz.\n"
                "3. **Dengeli BakÄ±ÅŸ AÃ§Ä±sÄ±:** Hem olumlu hem olumsuz yÃ¶nleri kÄ±saca belirt.\n"
                "4. **Genel DeÄŸerlendirme FormatÄ±:**\n"
                "    - **Genel DeÄŸerlendirme:** YorumlarÄ±n genel havasÄ±nÄ± Ã¶zetleyen kÄ±sa bir paragraf (olumlu/olumsuz yÃ¶nler dahil).\n"
                "    - **SonuÃ§:** KÄ±sa bir tavsiye veya Ã¶zet.\n"
                "5. **Gereksiz Detaylardan KaÃ§Ä±n:** Uzun listeler ve Ã§ok fazla alÄ±ntÄ± yapma.\n"
                "-----------------------------------\n\n"
                f"**KULLANICININ SORUSU:** {question}\n\n"
                "**GENEL DEÄERLENDÄ°RME (KÄ±sa ve Ã¶z, TÃ¼rkÃ§e):**"
            )
            
            Logger.debug("Prompt oluÅŸturuldu")
            return prompt
            
        except Exception as e:
            Logger.error(f"Prompt oluÅŸturma hatasÄ±: {e}")
            raise RAGServiceError(f"Prompt oluÅŸturulamadÄ±: {e}")
    
    def query_rag(self, question: str) -> str:
        """Tam RAG sorgu iÅŸlemini gerÃ§ekleÅŸtirir"""
        try:
            Logger.info(f"RAG sorgusu baÅŸlatÄ±lÄ±yor: {question}")
            
            # Index ve chunks'larÄ± her zaman yeniden yÃ¼kle (gÃ¼ncel veriler iÃ§in)
            self._loaded = False  # Force reload
            self.load_index_and_chunks()
            
            # YorumlarÄ± formatla
            all_reviews = []
            for i, chunk in enumerate(self._chunks):
                if isinstance(chunk, dict):
                    review_text = f"YORUM {i+1}: "
                    if 'comment' in chunk:
                        review_text += chunk['comment']
                    if 'rate' in chunk and chunk['rate'] > 0:
                        review_text += f" (Puan: {chunk['rate']}/5)"
                    if 'user' in chunk and chunk['user'] != 'Anonim':
                        review_text += f" (KullanÄ±cÄ±: {chunk['user']})"
                    all_reviews.append(review_text)
                elif isinstance(chunk, str):
                    all_reviews.append(f"YORUM {i+1}: {chunk}")
            
            top_chunks = all_reviews
            Logger.info(f"{len(top_chunks)} yorum formatlandÄ±")
            
            # ÃœrÃ¼n istatistiklerini Ã§Ä±kar
            product_stats = self.extract_product_stats(self._chunks)
            
            # Prompt oluÅŸtur
            prompt = self.build_prompt(question, top_chunks, product_stats)
            
            # AI'dan yanÄ±t al
            response = self._ai_service.generate_response(prompt)
            
            # YanÄ±tÄ± formatla
            final_response = self._add_review_count_to_response(
                response, len(self._chunks), len(top_chunks)
            )
            
            Logger.info("RAG sorgu iÅŸlemi baÅŸarÄ±yla tamamlandÄ±")
            return final_response
            
        except Exception as e:
            Logger.error(f"RAG sorgu hatasÄ±: {e}")
            raise RAGServiceError(f"RAG sorgusu baÅŸarÄ±sÄ±z: {e}")
    
    def _add_review_count_to_response(self, response_text: str, total_chunks: int, used_chunks: int) -> str:
        """AI cevabÄ±nÄ±n sonuna yorum sayÄ±sÄ±nÄ± ekler"""
        review_count_info = f"\n\n---\nğŸ“Š **Test Bilgisi**: Bu analiz {used_chunks}/{total_chunks} yorumdan oluÅŸturulmuÅŸtur."
        return response_text + review_count_info


class MockRAGService(IRAGService):
    """Test iÃ§in mock RAG service"""
    
    def __init__(self, mock_chunks: Optional[List[str]] = None):
        self._mock_chunks = mock_chunks or ["Mock yorum 1", "Mock yorum 2", "Mock yorum 3"]
        self._loaded = True
    
    def load_index_and_chunks(self) -> tuple:
        """Mock index ve chunks dÃ¶ndÃ¼rÃ¼r"""
        return None, self._mock_chunks
    
    def get_top_chunks(self, question: str, top_k: int = 5) -> List[str]:
        """Mock top chunks dÃ¶ndÃ¼rÃ¼r"""
        return self._mock_chunks[:min(top_k, len(self._mock_chunks))]
    
    def extract_product_stats(self, chunks: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Mock istatistikler dÃ¶ndÃ¼rÃ¼r"""
        return {
            'ortalamaPuan': 4.2,
            'toplamDegerlendirme': len(chunks),
            'pozitifYorumlar': 2,
            'negatifYorumlar': 1,
            'nÃ¶trYorumlar': 0
        }
    
    def build_prompt(self, question: str, top_chunks: List[str], product_stats: Dict[str, Any]) -> str:
        """Mock prompt dÃ¶ndÃ¼rÃ¼r"""
        return f"Mock prompt: {question}"
    
    def query_rag(self, question: str) -> str:
        """Mock RAG sorgu iÅŸlemi"""
        Logger.info(f"Mock RAG sorgusu: {question}")
        
        # Mock yanÄ±t
        mock_response = f"Mock AI yanÄ±tÄ±: {question} sorusuna gÃ¶re bu Ã¼rÃ¼n genel olarak kaliteli gÃ¶rÃ¼nÃ¼yor."
        
        # Mock review count ekle
        final_response = f"{mock_response}\n\n---\nğŸ“Š **Test Bilgisi**: Bu analiz 3/3 yorumdan oluÅŸturulmuÅŸtur."
        
        Logger.info("Mock RAG sorgu iÅŸlemi tamamlandÄ±")
        return final_response 